{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Vote</th>\n",
       "      <th>Ranked</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Members</th>\n",
       "      <th>Favorite</th>\n",
       "      <th>Volumes</th>\n",
       "      <th>Chapters</th>\n",
       "      <th>Status</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Author</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Mixed Feelings</th>\n",
       "      <th>Not Recommended</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Time from release (months)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berserk</td>\n",
       "      <td>9.47</td>\n",
       "      <td>331288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>665300</td>\n",
       "      <td>122841</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>['Action', 'Adventure', 'Award Winning', 'Dram...</td>\n",
       "      <td>['Miura Kentarou Studio Gaga']</td>\n",
       "      <td>233</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1989-08-25</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JoJo no Kimyou na Bouken Part 7: Steel Ball Run</td>\n",
       "      <td>9.30</td>\n",
       "      <td>156368</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>256146</td>\n",
       "      <td>42864</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>['Action', 'Adventure', 'Mystery', 'Supernatur...</td>\n",
       "      <td>['Araki Hirohiko']</td>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-01-19</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vagabond</td>\n",
       "      <td>9.24</td>\n",
       "      <td>136403</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>364891</td>\n",
       "      <td>40158</td>\n",
       "      <td>37.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>On Hiatus</td>\n",
       "      <td>['Action', 'Adventure', 'Award Winning']</td>\n",
       "      <td>['Inoue Takehiko Yoshikawa Eiji']</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1998-09-03</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One Piece</td>\n",
       "      <td>9.22</td>\n",
       "      <td>366668</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>599278</td>\n",
       "      <td>114531</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>['Action', 'Adventure', 'Fantasy']</td>\n",
       "      <td>['Oda Eiichiro']</td>\n",
       "      <td>173</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>1997-07-22</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monster</td>\n",
       "      <td>9.15</td>\n",
       "      <td>93945</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>236355</td>\n",
       "      <td>20501</td>\n",
       "      <td>18.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>['Award Winning', 'Drama', 'Mystery']</td>\n",
       "      <td>['Urasawa Naoki']</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1994-12-05</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title  Score    Vote  Ranked  \\\n",
       "0                                          Berserk   9.47  331288       1   \n",
       "1  JoJo no Kimyou na Bouken Part 7: Steel Ball Run   9.30  156368       2   \n",
       "2                                         Vagabond   9.24  136403       3   \n",
       "3                                        One Piece   9.22  366668       4   \n",
       "4                                          Monster   9.15   93945       5   \n",
       "\n",
       "   Popularity  Members  Favorite  Volumes  Chapters      Status  \\\n",
       "0           1   665300    122841      4.0      23.0  Publishing   \n",
       "1          26   256146     42864     24.0      96.0    Finished   \n",
       "2          15   364891     40158     37.0     327.0   On Hiatus   \n",
       "3           3   599278    114531      4.0      23.0  Publishing   \n",
       "4          29   236355     20501     18.0     162.0    Finished   \n",
       "\n",
       "                                              Genres  \\\n",
       "0  ['Action', 'Adventure', 'Award Winning', 'Dram...   \n",
       "1  ['Action', 'Adventure', 'Mystery', 'Supernatur...   \n",
       "2           ['Action', 'Adventure', 'Award Winning']   \n",
       "3                 ['Action', 'Adventure', 'Fantasy']   \n",
       "4              ['Award Winning', 'Drama', 'Mystery']   \n",
       "\n",
       "                              Author  Recommended  Mixed Feelings  \\\n",
       "0     ['Miura Kentarou Studio Gaga']          233              15   \n",
       "1                 ['Araki Hirohiko']          120               7   \n",
       "2  ['Inoue Takehiko Yoshikawa Eiji']           88               8   \n",
       "3                   ['Oda Eiichiro']          173              17   \n",
       "4                  ['Urasawa Naoki']           64               7   \n",
       "\n",
       "   Not Recommended Release date  Time from release (months)  \n",
       "0               10   1989-08-25                         411  \n",
       "1                1   2004-01-19                          87  \n",
       "2                1   1998-09-03                         201  \n",
       "3               16   1997-07-22                         316  \n",
       "4                5   1994-12-05                          84  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manga_df = pd.read_csv('../data/processed_comic.csv')\n",
    "manga_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 1: Xử lý cột \"Genres\"\n",
    "# Tách các nhãn và sử dụng One-Hot Encoding\n",
    "genres = manga_df['Genres'].str.get_dummies(sep=', ')\n",
    "manga_df = pd.concat([manga_df, genres], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Train Accuracy: 50.70%\n",
      "Linear Regression Test Accuracy: -213618517759394486157312.00%\n",
      "Random Forest Train Accuracy: 95.61%\n",
      "Random Forest Test Accuracy: 70.75%\n",
      "XGBoost Train Accuracy: 92.62%\n",
      "XGBoost Test Accuracy: 68.21%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# shuffle dataset\n",
    "# manga_df = manga_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Bước 2: Xử lý cột \"Status\"\n",
    "# Sử dụng Label Encoding hoặc One-Hot Encoding\n",
    "le = LabelEncoder()\n",
    "manga_df['Status'] = le.fit_transform(manga_df['Status'])\n",
    "\n",
    "# Chọn các cột số để làm đặc trưng\n",
    "numeric_columns = ['Vote', 'Popularity', 'Members', 'Favorite', 'Volumes','Chapters', 'Recommended', 'Mixed Feelings', 'Not Recommended', 'Status']\n",
    "\n",
    "# Chọn cột 'Score' làm biến mục tiêu\n",
    "target_column = 'Score'\n",
    "\n",
    "# Lọc dữ liệu\n",
    "data = manga_df[numeric_columns + list(genres.columns) + [target_column]].dropna()\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "# Chia dữ liệu thành tập huấn luyện và tập temp (tổng cộng tập test và validation)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data.drop(target_column, axis=1), data[target_column], test_size=0.2, random_state=42)\n",
    "\n",
    "# Chia tập temp thành tập test và tập validation\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Hàm để thực hiện cross-validation và tính trung bình lỗi\n",
    "def cross_val(model, X, y, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    mse = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=kf)\n",
    "    return -mse.mean()\n",
    "\n",
    "# Huấn luyện các mô hình và đánh giá chúng\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'XGBoost': XGBRegressor()\n",
    "}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Tạo pipeline để tự động thực hiện chuẩn hóa và huấn luyện mô hình\n",
    "numeric_features = numeric_columns + list(genres.columns)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, numeric_features)\n",
    "    ])\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', model)])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    train_accuracy = pipeline.score(X_train, y_train)\n",
    "    test_accuracy = pipeline.score(X_test, y_test)\n",
    "    \n",
    "    print(f'{name} Train Accuracy: {train_accuracy * 100:.2f}%')\n",
    "    print(f'{name} Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Validation Loss: 292.531\n",
      "Epoch 2/50, Validation Loss: 48.990\n",
      "Epoch 3/50, Validation Loss: 10.072\n",
      "Epoch 4/50, Validation Loss: 7.605\n",
      "Epoch 5/50, Validation Loss: 6.518\n",
      "Epoch 6/50, Validation Loss: 5.653\n",
      "Epoch 7/50, Validation Loss: 5.015\n",
      "Epoch 8/50, Validation Loss: 4.527\n",
      "Epoch 9/50, Validation Loss: 4.215\n",
      "Epoch 10/50, Validation Loss: 4.003\n",
      "Epoch 11/50, Validation Loss: 3.816\n",
      "Epoch 12/50, Validation Loss: 3.721\n",
      "Epoch 13/50, Validation Loss: 3.566\n",
      "Epoch 14/50, Validation Loss: 3.488\n",
      "Epoch 15/50, Validation Loss: 3.495\n",
      "Epoch 16/50, Validation Loss: 3.415\n",
      "Epoch 17/50, Validation Loss: 3.487\n",
      "Epoch 18/50, Validation Loss: 3.367\n",
      "Epoch 19/50, Validation Loss: 3.368\n",
      "Epoch 20/50, Validation Loss: 3.355\n",
      "Epoch 21/50, Validation Loss: 3.333\n",
      "Epoch 22/50, Validation Loss: 3.316\n",
      "Epoch 23/50, Validation Loss: 3.353\n",
      "Epoch 24/50, Validation Loss: 3.358\n",
      "Epoch 25/50, Validation Loss: 3.323\n",
      "Epoch 26/50, Validation Loss: 3.454\n",
      "Epoch 27/50, Validation Loss: 3.311\n",
      "Epoch 28/50, Validation Loss: 3.461\n",
      "Epoch 29/50, Validation Loss: 3.368\n",
      "Epoch 30/50, Validation Loss: 3.409\n",
      "Epoch 31/50, Validation Loss: 3.411\n",
      "Epoch 32/50, Validation Loss: 3.334\n",
      "Epoch 33/50, Validation Loss: 3.436\n",
      "Epoch 34/50, Validation Loss: 3.452\n",
      "Epoch 35/50, Validation Loss: 3.420\n",
      "Epoch 36/50, Validation Loss: 3.560\n",
      "Epoch 37/50, Validation Loss: 3.466\n",
      "Epoch 38/50, Validation Loss: 3.490\n",
      "Epoch 39/50, Validation Loss: 3.538\n",
      "Epoch 40/50, Validation Loss: 3.599\n",
      "Epoch 41/50, Validation Loss: 3.605\n",
      "Epoch 42/50, Validation Loss: 3.561\n",
      "Epoch 43/50, Validation Loss: 3.660\n",
      "Epoch 44/50, Validation Loss: 3.638\n",
      "Epoch 45/50, Validation Loss: 3.785\n",
      "Epoch 46/50, Validation Loss: 3.752\n",
      "Epoch 47/50, Validation Loss: 3.818\n",
      "Epoch 48/50, Validation Loss: 3.922\n",
      "Epoch 49/50, Validation Loss: 4.000\n",
      "Epoch 50/50, Validation Loss: 4.050\n",
      "Train Mean Squared Error: 0.062, Train R^2 Score: 0.606\n",
      "Validation Mean Squared Error: 0.416, Validation R^2 Score: -1.235\n",
      "Test Mean Squared Error: 0.105, Test R^2 Score: 0.292\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Chia dữ liệu thành features và target\n",
    "X = data.drop(target_column, axis=1).values\n",
    "y = data[target_column].values\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Chia thành tập train, validation, test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Chuyển dữ liệu thành Tensor\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val).view(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test).view(-1, 1)\n",
    "\n",
    "# Tạo DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Xây dựng mô hình\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Hàm huấn luyện mô hình\n",
    "def train_model(model, train_loader, val_loader, num_epochs=50, lr=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, labels)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss.item():.3f}')\n",
    "\n",
    "# Hàm tính score\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "\n",
    "    mse = mean_squared_error(true_labels, predictions)\n",
    "    r2 = r2_score(true_labels, predictions)\n",
    "    return mse, r2\n",
    "\n",
    "\n",
    "# Tạo và huấn luyện mô hình\n",
    "input_size = X_train.shape[1]\n",
    "model = RegressionModel(input_size)\n",
    "train_model(model, train_loader, val_loader)\n",
    "\n",
    "# Đánh giá trên tập train\n",
    "train_mse, train_r2 = evaluate_model(model, train_loader)\n",
    "print(f'Train Mean Squared Error: {train_mse:.3f}, Train R^2 Score: {train_r2:.3f}')\n",
    "\n",
    "# Đánh giá trên tập validation\n",
    "val_mse, val_r2 = evaluate_model(model, val_loader)\n",
    "print(f'Validation Mean Squared Error: {val_mse:.3f}, Validation R^2 Score: {val_r2:.3f}')\n",
    "\n",
    "# Đánh giá trên tập test\n",
    "test_mse, test_r2 = evaluate_model(model, test_loader)\n",
    "print(f'Test Mean Squared Error: {test_mse:.3f}, Test R^2 Score: {test_r2:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Vote</th>\n",
       "      <th>Ranked</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Members</th>\n",
       "      <th>Favorite</th>\n",
       "      <th>Volumes</th>\n",
       "      <th>Chapters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.47</td>\n",
       "      <td>331288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>665300</td>\n",
       "      <td>122841</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.30</td>\n",
       "      <td>156368</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>256146</td>\n",
       "      <td>42864</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.24</td>\n",
       "      <td>136403</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>364891</td>\n",
       "      <td>40158</td>\n",
       "      <td>37.0</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.22</td>\n",
       "      <td>366668</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>599278</td>\n",
       "      <td>114531</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.15</td>\n",
       "      <td>93945</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>236355</td>\n",
       "      <td>20501</td>\n",
       "      <td>18.0</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>6.91</td>\n",
       "      <td>632</td>\n",
       "      <td>9856</td>\n",
       "      <td>9083</td>\n",
       "      <td>1878</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>6.91</td>\n",
       "      <td>488</td>\n",
       "      <td>9857</td>\n",
       "      <td>12964</td>\n",
       "      <td>1159</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>6.91</td>\n",
       "      <td>218</td>\n",
       "      <td>9860</td>\n",
       "      <td>11610</td>\n",
       "      <td>1354</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>6.91</td>\n",
       "      <td>137</td>\n",
       "      <td>9862</td>\n",
       "      <td>14815</td>\n",
       "      <td>954</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>6.91</td>\n",
       "      <td>302</td>\n",
       "      <td>9863</td>\n",
       "      <td>9688</td>\n",
       "      <td>1739</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6128 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Score    Vote  Ranked  Popularity  Members  Favorite  Volumes  Chapters\n",
       "0      9.47  331288       1           1   665300    122841      4.0      23.0\n",
       "1      9.30  156368       2          26   256146     42864     24.0      96.0\n",
       "2      9.24  136403       3          15   364891     40158     37.0     327.0\n",
       "3      9.22  366668       4           3   599278    114531      4.0      23.0\n",
       "4      9.15   93945       5          29   236355     20501     18.0     162.0\n",
       "...     ...     ...     ...         ...      ...       ...      ...       ...\n",
       "6123   6.91     632    9856        9083     1878         7      4.0      23.0\n",
       "6124   6.91     488    9857       12964     1159         1      1.0       5.0\n",
       "6125   6.91     218    9860       11610     1354        12      6.0      31.0\n",
       "6126   6.91     137    9862       14815      954         9     10.0      23.0\n",
       "6127   6.91     302    9863        9688     1739        14      4.0      23.0\n",
       "\n",
       "[6128 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manga_df= pd.read_csv('../data/processed_comic.csv')\n",
    "test_manga_df = manga_df.iloc[:,1:9]\n",
    "test_manga_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3676 1226 1226\n",
      "Epoch 1/200 - Train Loss: 59.59334373474121, Validation Loss: 59.54508590698242\n",
      "Epoch 2/200 - Train Loss: 58.61746268436826, Validation Loss: 58.52839660644531\n",
      "Epoch 3/200 - Train Loss: 57.65076295260725, Validation Loss: 57.55698776245117\n",
      "Epoch 4/200 - Train Loss: 56.74341280706997, Validation Loss: 56.61804962158203\n",
      "Epoch 5/200 - Train Loss: 55.86326572812837, Validation Loss: 55.69930648803711\n",
      "Epoch 6/200 - Train Loss: 54.964044702464136, Validation Loss: 54.79875946044922\n",
      "Epoch 7/200 - Train Loss: 54.09021857689167, Validation Loss: 53.92060089111328\n",
      "Epoch 8/200 - Train Loss: 53.26505871476798, Validation Loss: 53.054229736328125\n",
      "Epoch 9/200 - Train Loss: 52.424735628325365, Validation Loss: 52.20804214477539\n",
      "Epoch 10/200 - Train Loss: 51.607887531148975, Validation Loss: 51.36515426635742\n",
      "Epoch 11/200 - Train Loss: 50.78139601082638, Validation Loss: 50.55229187011719\n",
      "Epoch 12/200 - Train Loss: 49.97828384925579, Validation Loss: 49.74338912963867\n",
      "Epoch 13/200 - Train Loss: 49.18652225362843, Validation Loss: 48.948978424072266\n",
      "Epoch 14/200 - Train Loss: 48.41868413727859, Validation Loss: 48.167415618896484\n",
      "Epoch 15/200 - Train Loss: 47.642780172413794, Validation Loss: 47.38758087158203\n",
      "Epoch 16/200 - Train Loss: 46.87032272075785, Validation Loss: 46.62590789794922\n",
      "Epoch 17/200 - Train Loss: 46.125211189533104, Validation Loss: 45.86885452270508\n",
      "Epoch 18/200 - Train Loss: 45.38064377883385, Validation Loss: 45.11930465698242\n",
      "Epoch 19/200 - Train Loss: 44.64377304603313, Validation Loss: 44.382049560546875\n",
      "Epoch 20/200 - Train Loss: 43.915838636201, Validation Loss: 43.65612030029297\n",
      "Epoch 21/200 - Train Loss: 43.192048631865404, Validation Loss: 42.9336051940918\n",
      "Epoch 22/200 - Train Loss: 42.482336965100515, Validation Loss: 42.22505187988281\n",
      "Epoch 23/200 - Train Loss: 41.77488879499764, Validation Loss: 41.52143859863281\n",
      "Epoch 24/200 - Train Loss: 41.07044101583546, Validation Loss: 40.82781982421875\n",
      "Epoch 25/200 - Train Loss: 40.393720626831055, Validation Loss: 40.14324188232422\n",
      "Epoch 26/200 - Train Loss: 39.70356809681859, Validation Loss: 39.46311950683594\n",
      "Epoch 27/200 - Train Loss: 39.03019911667396, Validation Loss: 38.7906379699707\n",
      "Epoch 28/200 - Train Loss: 38.37507589932146, Validation Loss: 38.132259368896484\n",
      "Epoch 29/200 - Train Loss: 37.7172474039012, Validation Loss: 37.47242736816406\n",
      "Epoch 30/200 - Train Loss: 37.07507685957284, Validation Loss: 36.82524490356445\n",
      "Epoch 31/200 - Train Loss: 36.428732576041384, Validation Loss: 36.1842155456543\n",
      "Epoch 32/200 - Train Loss: 35.78110964544888, Validation Loss: 35.550392150878906\n",
      "Epoch 33/200 - Train Loss: 35.169488446465856, Validation Loss: 34.92384338378906\n",
      "Epoch 34/200 - Train Loss: 34.542322684978615, Validation Loss: 34.3124885559082\n",
      "Epoch 35/200 - Train Loss: 33.92776837842218, Validation Loss: 33.696102142333984\n",
      "Epoch 36/200 - Train Loss: 33.32180246813544, Validation Loss: 33.095245361328125\n",
      "Epoch 37/200 - Train Loss: 32.72582863117086, Validation Loss: 32.49604415893555\n",
      "Epoch 38/200 - Train Loss: 32.12761273877374, Validation Loss: 31.907428741455078\n",
      "Epoch 39/200 - Train Loss: 31.545679815884295, Validation Loss: 31.32180404663086\n",
      "Epoch 40/200 - Train Loss: 30.96597530101908, Validation Loss: 30.74959945678711\n",
      "Epoch 41/200 - Train Loss: 30.3946124767435, Validation Loss: 30.18217658996582\n",
      "Epoch 42/200 - Train Loss: 29.831915000389362, Validation Loss: 29.61994743347168\n",
      "Epoch 43/200 - Train Loss: 29.275134579888707, Validation Loss: 29.05510139465332\n",
      "Epoch 44/200 - Train Loss: 28.72228507337899, Validation Loss: 28.506772994995117\n",
      "Epoch 45/200 - Train Loss: 28.178863887129157, Validation Loss: 27.966901779174805\n",
      "Epoch 46/200 - Train Loss: 27.645826701460212, Validation Loss: 27.427658081054688\n",
      "Epoch 47/200 - Train Loss: 27.10584650368526, Validation Loss: 26.900936126708984\n",
      "Epoch 48/200 - Train Loss: 26.57779890915443, Validation Loss: 26.375452041625977\n",
      "Epoch 49/200 - Train Loss: 26.06413173675537, Validation Loss: 25.860279083251953\n",
      "Epoch 50/200 - Train Loss: 25.54716317407016, Validation Loss: 25.346994400024414\n",
      "Epoch 51/200 - Train Loss: 25.0416511996039, Validation Loss: 24.844316482543945\n",
      "Epoch 52/200 - Train Loss: 24.545836547325397, Validation Loss: 24.34421730041504\n",
      "Epoch 53/200 - Train Loss: 24.054919242858887, Validation Loss: 23.849952697753906\n",
      "Epoch 54/200 - Train Loss: 23.560186550535004, Validation Loss: 23.362173080444336\n",
      "Epoch 55/200 - Train Loss: 23.082794748503588, Validation Loss: 22.883398056030273\n",
      "Epoch 56/200 - Train Loss: 22.60977866731841, Validation Loss: 22.411706924438477\n",
      "Epoch 57/200 - Train Loss: 22.133627365375386, Validation Loss: 21.944082260131836\n",
      "Epoch 58/200 - Train Loss: 21.67319235308417, Validation Loss: 21.481822967529297\n",
      "Epoch 59/200 - Train Loss: 21.21370946949926, Validation Loss: 21.028594970703125\n",
      "Epoch 60/200 - Train Loss: 20.770613275725267, Validation Loss: 20.5773983001709\n",
      "Epoch 61/200 - Train Loss: 20.318037789443444, Validation Loss: 20.13544273376465\n",
      "Epoch 62/200 - Train Loss: 19.879883272894496, Validation Loss: 19.69491958618164\n",
      "Epoch 63/200 - Train Loss: 19.447173874953698, Validation Loss: 19.26432228088379\n",
      "Epoch 64/200 - Train Loss: 19.017887312790442, Validation Loss: 18.841815948486328\n",
      "Epoch 65/200 - Train Loss: 18.595134767992743, Validation Loss: 18.419965744018555\n",
      "Epoch 66/200 - Train Loss: 18.177270396002406, Validation Loss: 18.003515243530273\n",
      "Epoch 67/200 - Train Loss: 17.76926043937946, Validation Loss: 17.594566345214844\n",
      "Epoch 68/200 - Train Loss: 17.36269733823579, Validation Loss: 17.191795349121094\n",
      "Epoch 69/200 - Train Loss: 16.959443454084724, Validation Loss: 16.793752670288086\n",
      "Epoch 70/200 - Train Loss: 16.566945240415375, Validation Loss: 16.40302085876465\n",
      "Epoch 71/200 - Train Loss: 16.1787361605414, Validation Loss: 16.016841888427734\n",
      "Epoch 72/200 - Train Loss: 15.79826754537122, Validation Loss: 15.638859748840332\n",
      "Epoch 73/200 - Train Loss: 15.420675918973725, Validation Loss: 15.258829116821289\n",
      "Epoch 74/200 - Train Loss: 15.047659397125244, Validation Loss: 14.89034652709961\n",
      "Epoch 75/200 - Train Loss: 14.679525539792817, Validation Loss: 14.529594421386719\n",
      "Epoch 76/200 - Train Loss: 14.320661232389252, Validation Loss: 14.166657447814941\n",
      "Epoch 77/200 - Train Loss: 13.969111179483347, Validation Loss: 13.816581726074219\n",
      "Epoch 78/200 - Train Loss: 13.614884804035055, Validation Loss: 13.465447425842285\n",
      "Epoch 79/200 - Train Loss: 13.269973097176388, Validation Loss: 13.123697280883789\n",
      "Epoch 80/200 - Train Loss: 12.930070893517856, Validation Loss: 12.786359786987305\n",
      "Epoch 81/200 - Train Loss: 12.600031490983634, Validation Loss: 12.453886032104492\n",
      "Epoch 82/200 - Train Loss: 12.268610165036957, Validation Loss: 12.128507614135742\n",
      "Epoch 83/200 - Train Loss: 11.947286441408355, Validation Loss: 11.808403015136719\n",
      "Epoch 84/200 - Train Loss: 11.626831104015482, Validation Loss: 11.491641998291016\n",
      "Epoch 85/200 - Train Loss: 11.316684903769657, Validation Loss: 11.178189277648926\n",
      "Epoch 86/200 - Train Loss: 11.005251193868704, Validation Loss: 10.874147415161133\n",
      "Epoch 87/200 - Train Loss: 10.705680288117508, Validation Loss: 10.574135780334473\n",
      "Epoch 88/200 - Train Loss: 10.40164903114582, Validation Loss: 10.276127815246582\n",
      "Epoch 89/200 - Train Loss: 10.115168127520331, Validation Loss: 9.98592472076416\n",
      "Epoch 90/200 - Train Loss: 9.82687363131293, Validation Loss: 9.701678276062012\n",
      "Epoch 91/200 - Train Loss: 9.541306479223843, Validation Loss: 9.421931266784668\n",
      "Epoch 92/200 - Train Loss: 9.267523288726807, Validation Loss: 9.145162582397461\n",
      "Epoch 93/200 - Train Loss: 8.993213472695187, Validation Loss: 8.87539005279541\n",
      "Epoch 94/200 - Train Loss: 8.72755978025239, Validation Loss: 8.611865997314453\n",
      "Epoch 95/200 - Train Loss: 8.464015056347025, Validation Loss: 8.351202011108398\n",
      "Epoch 96/200 - Train Loss: 8.203660479907331, Validation Loss: 8.095130920410156\n",
      "Epoch 97/200 - Train Loss: 7.954772365504298, Validation Loss: 7.845057010650635\n",
      "Epoch 98/200 - Train Loss: 7.708121595711543, Validation Loss: 7.597811698913574\n",
      "Epoch 99/200 - Train Loss: 7.462278579843455, Validation Loss: 7.358412742614746\n",
      "Epoch 100/200 - Train Loss: 7.225847803313156, Validation Loss: 7.122098922729492\n",
      "Epoch 101/200 - Train Loss: 6.990895665925125, Validation Loss: 6.890600204467773\n",
      "Epoch 102/200 - Train Loss: 6.76225000414355, Validation Loss: 6.663722038269043\n",
      "Epoch 103/200 - Train Loss: 6.539103672422212, Validation Loss: 6.442480087280273\n",
      "Epoch 104/200 - Train Loss: 6.319873867363765, Validation Loss: 6.2251176834106445\n",
      "Epoch 105/200 - Train Loss: 6.106068652251671, Validation Loss: 6.01319694519043\n",
      "Epoch 106/200 - Train Loss: 5.8944016900555845, Validation Loss: 5.803449630737305\n",
      "Epoch 107/200 - Train Loss: 5.6882741944543245, Validation Loss: 5.598662376403809\n",
      "Epoch 108/200 - Train Loss: 5.488726878988332, Validation Loss: 5.400142669677734\n",
      "Epoch 109/200 - Train Loss: 5.291369183310147, Validation Loss: 5.206348419189453\n",
      "Epoch 110/200 - Train Loss: 5.10120335940657, Validation Loss: 5.016566276550293\n",
      "Epoch 111/200 - Train Loss: 4.91428960602859, Validation Loss: 4.830962657928467\n",
      "Epoch 112/200 - Train Loss: 4.72981622301299, Validation Loss: 4.649834632873535\n",
      "Epoch 113/200 - Train Loss: 4.550360441207886, Validation Loss: 4.473455905914307\n",
      "Epoch 114/200 - Train Loss: 4.377778094390343, Validation Loss: 4.2996320724487305\n",
      "Epoch 115/200 - Train Loss: 4.2074261369376345, Validation Loss: 4.1321611404418945\n",
      "Epoch 116/200 - Train Loss: 4.03809299140141, Validation Loss: 3.9675114154815674\n",
      "Epoch 117/200 - Train Loss: 3.8782323105581877, Validation Loss: 3.8078839778900146\n",
      "Epoch 118/200 - Train Loss: 3.7200329303741455, Validation Loss: 3.65312123298645\n",
      "Epoch 119/200 - Train Loss: 3.5675314541520744, Validation Loss: 3.5015740394592285\n",
      "Epoch 120/200 - Train Loss: 3.41842691651706, Validation Loss: 3.3547861576080322\n",
      "Epoch 121/200 - Train Loss: 3.2743419902078035, Validation Loss: 3.211087703704834\n",
      "Epoch 122/200 - Train Loss: 3.1318033563679664, Validation Loss: 3.0719735622406006\n",
      "Epoch 123/200 - Train Loss: 2.995729557399092, Validation Loss: 2.936929225921631\n",
      "Epoch 124/200 - Train Loss: 2.8632686878072806, Validation Loss: 2.8049535751342773\n",
      "Epoch 125/200 - Train Loss: 2.7328157630460015, Validation Loss: 2.677178382873535\n",
      "Epoch 126/200 - Train Loss: 2.610241141812555, Validation Loss: 2.553706169128418\n",
      "Epoch 127/200 - Train Loss: 2.486745065656202, Validation Loss: 2.434109926223755\n",
      "Epoch 128/200 - Train Loss: 2.3697198670485924, Validation Loss: 2.3184125423431396\n",
      "Epoch 129/200 - Train Loss: 2.2564750580952087, Validation Loss: 2.20640230178833\n",
      "Epoch 130/200 - Train Loss: 2.1452676674415327, Validation Loss: 2.097931146621704\n",
      "Epoch 131/200 - Train Loss: 2.0378983452402313, Validation Loss: 1.9931334257125854\n",
      "Epoch 132/200 - Train Loss: 1.934886883045065, Validation Loss: 1.892054796218872\n",
      "Epoch 133/200 - Train Loss: 1.8365023691078712, Validation Loss: 1.7936017513275146\n",
      "Epoch 134/200 - Train Loss: 1.7398293696600815, Validation Loss: 1.6993657350540161\n",
      "Epoch 135/200 - Train Loss: 1.6475378316024254, Validation Loss: 1.6087009906768799\n",
      "Epoch 136/200 - Train Loss: 1.5589353976578548, Validation Loss: 1.5208194255828857\n",
      "Epoch 137/200 - Train Loss: 1.4750328988864505, Validation Loss: 1.4370561838150024\n",
      "Epoch 138/200 - Train Loss: 1.3914184775845757, Validation Loss: 1.355332851409912\n",
      "Epoch 139/200 - Train Loss: 1.3119710087776184, Validation Loss: 1.278359293937683\n",
      "Epoch 140/200 - Train Loss: 1.23539779515102, Validation Loss: 1.203343152999878\n",
      "Epoch 141/200 - Train Loss: 1.1630105437903568, Validation Loss: 1.1318241357803345\n",
      "Epoch 142/200 - Train Loss: 1.0928862608712295, Validation Loss: 1.063105821609497\n",
      "Epoch 143/200 - Train Loss: 1.0251623649021675, Validation Loss: 0.9975666403770447\n",
      "Epoch 144/200 - Train Loss: 0.9616046856189596, Validation Loss: 0.9348576664924622\n",
      "Epoch 145/200 - Train Loss: 0.9006646254966999, Validation Loss: 0.8749876618385315\n",
      "Epoch 146/200 - Train Loss: 0.8434579218256062, Validation Loss: 0.8179991245269775\n",
      "Epoch 147/200 - Train Loss: 0.7871384970073042, Validation Loss: 0.7632851004600525\n",
      "Epoch 148/200 - Train Loss: 0.7341136809053093, Validation Loss: 0.7119180560112\n",
      "Epoch 149/200 - Train Loss: 0.6843199216086289, Validation Loss: 0.6628086566925049\n",
      "Epoch 150/200 - Train Loss: 0.6361809157091995, Validation Loss: 0.6160981059074402\n",
      "Epoch 151/200 - Train Loss: 0.5913255050264555, Validation Loss: 0.572145402431488\n",
      "Epoch 152/200 - Train Loss: 0.5489558176747684, Validation Loss: 0.53018718957901\n",
      "Epoch 153/200 - Train Loss: 0.5072882139477236, Validation Loss: 0.49075356125831604\n",
      "Epoch 154/200 - Train Loss: 0.4695363337623662, Validation Loss: 0.45375576615333557\n",
      "Epoch 155/200 - Train Loss: 0.4329448892124768, Validation Loss: 0.4185674488544464\n",
      "Epoch 156/200 - Train Loss: 0.39962965198631945, Validation Loss: 0.3854842483997345\n",
      "Epoch 157/200 - Train Loss: 0.36773199254068833, Validation Loss: 0.3545801639556885\n",
      "Epoch 158/200 - Train Loss: 0.33763518158731787, Validation Loss: 0.3256237804889679\n",
      "Epoch 159/200 - Train Loss: 0.3102415332506443, Validation Loss: 0.29855987429618835\n",
      "Epoch 160/200 - Train Loss: 0.2845060370605567, Validation Loss: 0.2732026278972626\n",
      "Epoch 161/200 - Train Loss: 0.25997997871760664, Validation Loss: 0.2496870756149292\n",
      "Epoch 162/200 - Train Loss: 0.23703233538002805, Validation Loss: 0.22773431241512299\n",
      "Epoch 163/200 - Train Loss: 0.21572048191366525, Validation Loss: 0.20743927359580994\n",
      "Epoch 164/200 - Train Loss: 0.19646130065465794, Validation Loss: 0.1887110024690628\n",
      "Epoch 165/200 - Train Loss: 0.17837476139438563, Validation Loss: 0.17128194868564606\n",
      "Epoch 166/200 - Train Loss: 0.1620630205705248, Validation Loss: 0.1553923636674881\n",
      "Epoch 167/200 - Train Loss: 0.14706220233748699, Validation Loss: 0.1407013088464737\n",
      "Epoch 168/200 - Train Loss: 0.1327229104936123, Validation Loss: 0.1271989941596985\n",
      "Epoch 169/200 - Train Loss: 0.12008922971014319, Validation Loss: 0.11490059643983841\n",
      "Epoch 170/200 - Train Loss: 0.10860219148212466, Validation Loss: 0.10371142625808716\n",
      "Epoch 171/200 - Train Loss: 0.09823671664143431, Validation Loss: 0.09360802918672562\n",
      "Epoch 172/200 - Train Loss: 0.08826586771114119, Validation Loss: 0.08440797030925751\n",
      "Epoch 173/200 - Train Loss: 0.07959057531993964, Validation Loss: 0.07610020786523819\n",
      "Epoch 174/200 - Train Loss: 0.07174699348879271, Validation Loss: 0.06863763183355331\n",
      "Epoch 175/200 - Train Loss: 0.0650145310009348, Validation Loss: 0.061897266656160355\n",
      "Epoch 176/200 - Train Loss: 0.05864771391297209, Validation Loss: 0.055879659950733185\n",
      "Epoch 177/200 - Train Loss: 0.0530662100826358, Validation Loss: 0.050520747900009155\n",
      "Epoch 178/200 - Train Loss: 0.04819290522999804, Validation Loss: 0.045780982822179794\n",
      "Epoch 179/200 - Train Loss: 0.04355594307055761, Validation Loss: 0.04156111180782318\n",
      "Epoch 180/200 - Train Loss: 0.03983463969980848, Validation Loss: 0.037915412336587906\n",
      "Epoch 181/200 - Train Loss: 0.03645290672008333, Validation Loss: 0.03467799350619316\n",
      "Epoch 182/200 - Train Loss: 0.03343889069069048, Validation Loss: 0.031850334256887436\n",
      "Epoch 183/200 - Train Loss: 0.03078776220630469, Validation Loss: 0.02939826063811779\n",
      "Epoch 184/200 - Train Loss: 0.028541264702276938, Validation Loss: 0.02729838714003563\n",
      "Epoch 185/200 - Train Loss: 0.026718151579000825, Validation Loss: 0.025469660758972168\n",
      "Epoch 186/200 - Train Loss: 0.025066319098374968, Validation Loss: 0.023868359625339508\n",
      "Epoch 187/200 - Train Loss: 0.02389378039615935, Validation Loss: 0.022589275613427162\n",
      "Epoch 188/200 - Train Loss: 0.02240609257192961, Validation Loss: 0.02138872817158699\n",
      "Epoch 189/200 - Train Loss: 0.021522818534667122, Validation Loss: 0.020429285243153572\n",
      "Epoch 190/200 - Train Loss: 0.02077269965204699, Validation Loss: 0.019613496959209442\n",
      "Epoch 191/200 - Train Loss: 0.019754821691533614, Validation Loss: 0.01893829181790352\n",
      "Epoch 192/200 - Train Loss: 0.019340265654669755, Validation Loss: 0.018415214493870735\n",
      "Epoch 193/200 - Train Loss: 0.01881683091151303, Validation Loss: 0.017881862819194794\n",
      "Epoch 194/200 - Train Loss: 0.01829830606082647, Validation Loss: 0.017515670508146286\n",
      "Epoch 195/200 - Train Loss: 0.01797556058214656, Validation Loss: 0.017176898196339607\n",
      "Epoch 196/200 - Train Loss: 0.01767397172556355, Validation Loss: 0.01694338582456112\n",
      "Epoch 197/200 - Train Loss: 0.017655268279385978, Validation Loss: 0.016724232584238052\n",
      "Epoch 198/200 - Train Loss: 0.017484835188450485, Validation Loss: 0.016524463891983032\n",
      "Epoch 199/200 - Train Loss: 0.01727219612401878, Validation Loss: 0.016491524875164032\n",
      "Epoch 200/200 - Train Loss: 0.017036718814152068, Validation Loss: 0.016216274350881577\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.019901374657355288, 0.8808805223147711\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(test_manga_df.drop('Score', axis=1), test_manga_df['Score'], test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "print(len(X_train), len(X_test), len(X_val))\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors and create DataLoader\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define your linear regression model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Initialize model, loss function, optimizer\n",
    "model = LinearRegressionModel(input_size=X_train.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Choose your optimizer and learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(average_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {average_loss}, Validation Loss: {val_loss.item()}')\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model.state_dict()\n",
    "# Plot the training and validation losses over epochs\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "# Test the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_mse = mean_squared_error(y_test, test_outputs.numpy())\n",
    "    test_r2 = r2_score(y_test, test_outputs.numpy())\n",
    "print(f'Mean Squared Error on Test Set: {test_mse}, {test_r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
